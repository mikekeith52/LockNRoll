{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "class DDPGagent:\n",
    "    def __init__(self, hidden_size=256, actor_learning_rate=1e-4, critic_learning_rate=1e-3, gamma=0.99, tau=1e-2, max_memory_size=50000):\n",
    "        # Params\n",
    "        self.num_states = 3\n",
    "        self.num_actions = 100\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "        # Networks\n",
    "        self.actor = Actor(self.num_states, hidden_size, self.num_actions)\n",
    "        self.actor_target = Actor(self.num_states, hidden_size, self.num_actions)\n",
    "        self.critic = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions)\n",
    "        self.critic_target = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions)\n",
    "\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "\n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "        \n",
    "        # Training\n",
    "        self.memory = Memory(max_memory_size)        \n",
    "        self.critic_criterion  = nn.MSELoss()\n",
    "        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=actor_learning_rate)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_learning_rate)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
    "        action = self.actor.forward(state)\n",
    "        action = action.detach().numpy()[0,0]\n",
    "        return action\n",
    "    \n",
    "    def update(self, batch_size):\n",
    "        states, actions, rewards, next_states, _ = self.memory.sample(batch_size)\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.FloatTensor(actions)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.FloatTensor(next_states)\n",
    "    \n",
    "        # Critic loss        \n",
    "        Qvals = self.critic.forward(states, actions)\n",
    "        next_actions = self.actor_target.forward(next_states)\n",
    "        next_Q = self.critic_target.forward(next_states, next_actions.detach())\n",
    "        Qprime = rewards + self.gamma * next_Q\n",
    "        critic_loss = self.critic_criterion(Qvals, Qprime)\n",
    "\n",
    "        # Actor loss\n",
    "        policy_loss = -self.critic.forward(states, self.actor.forward(states)).mean()\n",
    "        \n",
    "        # update networks\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward() \n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # update target networks \n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))\n",
    "       \n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DDPGagent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = Variable(torch.from_numpy(state)).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.actor.forward(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = action.detach().numpy()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008645908"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.64590798e-03,  5.05254306e-02,  6.88214749e-02,\n",
       "         6.84536994e-02,  5.63129410e-02, -4.08938117e-02,\n",
       "         1.62545457e-01, -1.93836302e-01,  1.81970615e-02,\n",
       "         2.53921360e-01, -6.58428520e-02,  3.52929235e-02,\n",
       "         3.48545536e-02, -6.70218691e-02, -6.72469884e-02,\n",
       "        -5.60472999e-03,  6.42209128e-02,  1.35742575e-01,\n",
       "         1.59838691e-01, -1.93911176e-02, -1.14204340e-01,\n",
       "        -2.06554905e-01,  4.50151712e-02, -1.55493617e-05,\n",
       "        -2.77051572e-02, -1.88837592e-02,  8.53493810e-02,\n",
       "         6.52661547e-02,  1.50352707e-02,  2.02887431e-01,\n",
       "         1.31309286e-01,  1.07920811e-01, -6.15683086e-02,\n",
       "         5.57933301e-02,  1.63974136e-01,  8.74372497e-02,\n",
       "         1.28084257e-01, -3.76115330e-02,  9.03327763e-03,\n",
       "        -6.62251487e-02,  7.38179833e-02, -1.37300029e-01,\n",
       "         1.37285382e-01,  2.19473705e-01, -4.14418690e-02,\n",
       "         5.86240552e-02, -1.89701304e-01,  1.36127705e-02,\n",
       "         7.91407656e-03, -6.32426888e-02, -5.81539162e-02,\n",
       "        -9.44835774e-04, -1.39789935e-03,  5.89687601e-02,\n",
       "        -1.75072789e-01,  7.46520013e-02, -7.20939785e-02,\n",
       "         2.13073157e-02, -5.86047843e-02, -1.04195036e-01,\n",
       "        -1.02416284e-01,  1.14175484e-01, -7.57209733e-02,\n",
       "        -4.05601747e-02, -1.44168124e-01,  6.14384823e-02,\n",
       "        -2.20304020e-02,  3.54443826e-02,  7.67060043e-03,\n",
       "        -3.02041359e-02, -5.28570190e-02, -7.79906437e-02,\n",
       "        -3.74750979e-02, -1.91111565e-01, -6.85110409e-03,\n",
       "        -5.73140197e-02, -2.90317666e-02, -3.65128228e-03,\n",
       "         4.44256999e-02, -2.22087968e-02,  8.80175233e-02,\n",
       "        -9.23146680e-02,  7.20327422e-02, -2.12257449e-02,\n",
       "        -8.37058574e-02, -3.73222446e-03, -8.78962353e-02,\n",
       "        -2.55419552e-01, -3.38634253e-02,  1.17166080e-01,\n",
       "        -3.37096229e-02,  1.78915262e-01, -7.48459995e-02,\n",
       "        -3.30916829e-02, -2.55273767e-02, -2.29277894e-01,\n",
       "         4.39507701e-02, -3.89956199e-02,  6.71199188e-02,\n",
       "        -4.59426641e-02]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
